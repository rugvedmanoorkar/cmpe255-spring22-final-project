{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-10T02:31:19.074059Z","iopub.execute_input":"2022-05-10T02:31:19.074683Z","iopub.status.idle":"2022-05-10T02:31:19.079251Z","shell.execute_reply.started":"2022-05-10T02:31:19.074638Z","shell.execute_reply":"2022-05-10T02:31:19.078467Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"## Problem\n\n#### * Pneumonia can range from a mild to serious or life-threatening infection and can sometimes lead to death.\n#### * Detected using X-ray imaging.\n#### * Commonly misclassified as other diseases since radiographs are not particularly clear.\n\n## Proposed Solution\n\n#### * Machine learning models can be used to identify pneumonia in chest X-rays\n#### * Intend to develop robust classifiers using Support Vector Machine (SVM) machine learning technique  to detect the presence of Pneumonia in chest X-ray images\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T02:31:23.285428Z","iopub.execute_input":"2022-05-10T02:31:23.285686Z","iopub.status.idle":"2022-05-10T02:31:23.290385Z","shell.execute_reply.started":"2022-05-10T02:31:23.285658Z","shell.execute_reply":"2022-05-10T02:31:23.289644Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom scipy import stats","metadata":{"execution":{"iopub.status.busy":"2022-05-10T02:31:28.269052Z","iopub.execute_input":"2022-05-10T02:31:28.269924Z","iopub.status.idle":"2022-05-10T02:31:29.180068Z","shell.execute_reply.started":"2022-05-10T02:31:28.269868Z","shell.execute_reply":"2022-05-10T02:31:29.179136Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Dataset\n\n#### * 5856 labelled chest X-rays\n#### * 4273 X-ray images are from different subjects affected by pneumonia\n#### *1583 X-ray images are labelled as not having pneumonia.\nhttps://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\n","metadata":{}},{"cell_type":"markdown","source":"## Dataset and Preprocessing\n\n#### * High quality JPEG images with resolution of at least 1280 x 720 pixels\n#### * Image -> Grayscale -> Resize \n#### * ‘1’ - pneumonia (positive) samples\n#### * ‘0’- pneumonia (negative) samples\n","metadata":{}},{"cell_type":"code","source":"\ndef load_data(path, mode=\"train\"):\n\n    images = []\n    labels = []\n    img_size=256\n    normal_limit=1000\n    p_limit=1000    \n    \n    folder_names = []\n    for entry_name in os.listdir(path):\n        entry_path = os.path.join(path, entry_name)\n        if os.path.isdir(entry_path):\n            folder_names.append(entry_name)\n        \n    print('The Categories are',folder_names)\n    \n    if mode == \"train\":\n        for folder in folder_names:\n            if folder == \"PNEUMONIA\":\n                limit= p_limit\n            else:\n                limit= normal_limit\n            for idx, filename in enumerate(os.listdir(os.path.join(path,folder))):\n                img_path = os.path.join(path,folder)\n                img = cv2.imread(os.path.join(img_path,filename)) \n                if img is not None:\n                    img  = cv2.cvtColor(img , cv2.COLOR_BGR2GRAY)   \n                    img = cv2.resize(img,(img_size, img_size))\n                    images.append(img)\n                    if folder == 'NORMAL':\n                        labels.append(0)\n                        #print('normal')\n                    else:\n                        labels.append(1)\n                        #print('PNE')\n                if idx >= limit-1:\n                    break\n    else:\n        for folder in folder_names:\n            for idx, filename in enumerate(os.listdir(os.path.join(path,folder))):\n                img_path = os.path.join(path,folder)\n                img = cv2.imread(os.path.join(img_path,filename)) \n                if img is not None:\n                    img  = cv2.cvtColor(img , cv2.COLOR_BGR2GRAY)   \n                    img = cv2.resize(img,(img_size, img_size))\n                    images.append(img)\n                    if folder == 'NORMAL':\n                        labels.append(0)\n                        #print('normal')\n                    else:\n                        labels.append(1)\n                        #print('PNE')\n            \n    images,labels=np.array(images),np.array(labels)\n    print(images.shape)\n    return images, labels\n#print(labels)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T02:31:32.929018Z","iopub.execute_input":"2022-05-10T02:31:32.929286Z","iopub.status.idle":"2022-05-10T02:31:32.942818Z","shell.execute_reply.started":"2022-05-10T02:31:32.929258Z","shell.execute_reply":"2022-05-10T02:31:32.941756Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Feature Extraction\n\n#### * Extract 10 features from all the images to form a feature vector for each sample: variance, mean, standard deviation, skew, kurtosis, entropy, canny edges, local binary pattern (LBP), Sobel X, and Sobel Y. [in progress]\n#### * LBP : Local Binary Pattern (LBP) is a simple yet very efficient texture operator which labels the pixels of an image by thresholding the neighborhood of each pixel and considers the result as a binary number\n#### * Canny Edges : makes it easy to segment the image (break it up into separate objects or areas), which can then be recognised separately.\n#### * Entropy : defined as corresponding states of intensity level which individual pixels can adapt. It is used in the quantitative analysis and evaluation image details, the entropy value is used as it provides better comparison of the image details\n","metadata":{}},{"cell_type":"code","source":"from skimage.feature import multiblock_lbp\nnormal_limit=1000\np_limit=1000  \nimg_size=256\n\ndef get_feature_vector(images):\n    kernel = np.ones((3,3),np.uint8)\n    #print(kernel)\n    var_vector = np.empty((len(images),1))\n    lbp_vector = np.empty((len(images),1))\n    mean_vector = np.empty((len(images),1))\n    std_vector = np.empty((len(images),1))\n    skew_vector = np.empty((len(images),1))\n    kurto_vector = np.empty((len(images),1))\n    entropy_vector = np.empty((len(images),1))\n    canny_vector = np.empty((len(images),img_size*img_size))\n    sobelX_vector = np.empty((len(images),img_size*img_size))\n    sobelY_vector = np.empty((len(images),img_size*img_size))\n\n    for idx, image in enumerate(images):\n        x, bins = np.histogram(image,bins=255, density=False)\n        var_vector[idx] = np.var(x)\n        \n        lbp = multiblock_lbp(image, 0,0,28,28)\n        lbp_vector[idx] = lbp\n        \n        mean_vector[idx] = np.mean(x)\n        std_vector[idx] = np.std(x)\n        skew_vector[idx] = stats.skew(x)\n        kurto_vector[idx] = stats.kurtosis(x)\n        entropy_vector[idx] = stats.entropy(x)\n        \n        canny = cv2.Canny(image,40,200)\n        canny_vector[idx] = np.array(canny.flatten())\n    \n        sobelX = cv2.Sobel(image,cv2.CV_8UC1,1,0,ksize=5)\n        sobelX_vector[idx] = np.array(sobelX.flatten())\n        sobelY = cv2.Sobel(image,cv2.CV_8UC1,0,1,ksize=5)\n        sobelY_vector[idx] = np.array(sobelY.flatten())\n    feature_vector = np.empty((len(images),0))\n    #feature_vector=np.append(feature_vector,mean_vector,axis=1)\n    feature_vector=np.append(feature_vector,lbp_vector,axis=1)\n    feature_vector=np.append(feature_vector,var_vector,axis=1)\n    feature_vector=np.append(feature_vector,std_vector,axis=1)\n    feature_vector=np.append(feature_vector,skew_vector,axis=1)\n    feature_vector=np.append(feature_vector,kurto_vector,axis=1)\n    feature_vector=np.append(feature_vector,entropy_vector,axis=1)\n    feature_vector=np.append(feature_vector,canny_vector,axis=1)\n    feature_vector=np.append(feature_vector,sobelX_vector,axis=1)\n    feature_vector=np.append(feature_vector,sobelY_vector,axis=1)\n    \n    return feature_vector\n\n# Load data\ntrain_path = \"../input/chest-xray-pneumonia/chest_xray/train/\"\ntest_path = \"../input/chest-xray-pneumonia/chest_xray/test/\"\n\nx_train_images,y_train = load_data(train_path,mode=\"train\")\nx_test_images, y_test = load_data(test_path)\n\n#feature_vector=np.append(feature_vector,,axis=1)\n\n# Generate features\nx_train = get_feature_vector(x_train_images)\n\nx_test = get_feature_vector(x_test_images)\n\nprint(x_test.shape)\nfrom random import randrange\nlimit = 1000\ni = randrange(limit*2)\n\nplt.imshow(x_train_images[i],cmap='gray')\nplt.xticks([])\nplt.yticks([])\nplt.show()\nprint(y_train[i])\n\n#Canny\ncanny = cv2.Canny(x_train_images[i],40,200)\n\n\n#Sobel\nsobelY = cv2.Sobel(x_train_images[i],cv2.CV_8UC1,0,1,ksize=5)\n\npreview = [canny,sobelY]\ni=0\nfor i in range(2):\n    plt.subplot(1,2,i+1)\n    plt.imshow(preview[i], cmap='gray')\n    plt.xticks([])\n    plt.yticks([])\nplt.show()\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.fit_transform(x_test)\n# print(xtest)\n\n# Shuffle train data\nfrom sklearn.utils import shuffle\n\nx_train, y_train = shuffle(x_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T02:31:42.913458Z","iopub.execute_input":"2022-05-10T02:31:42.913763Z","iopub.status.idle":"2022-05-10T02:33:01.169077Z","shell.execute_reply.started":"2022-05-10T02:31:42.913729Z","shell.execute_reply":"2022-05-10T02:33:01.168222Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn import svm\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report\n\nclf = svm.SVC(kernel = \"linear\", random_state=0,probability = True)\n\n#scores = cross_val_score(clf, xtrain, ytrain, cv=5)\n#print(scores)\n#print(\"Cross validation Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n\nclf.fit(x_train, y_train)\nypredict_test = clf.predict(x_test)\n#print(clf.score(xtest,ytest))\n\nypredict_train = clf.predict(x_train)\nprint(\"Train Accuracy:\",metrics.accuracy_score(y_train, ypredict_train))\n\nprint(\"Test Accuracy:\",metrics.accuracy_score(y_test, ypredict_test))\n\ncm = confusion_matrix(y_test, ypredict_test)\n#cm = confusion_matrix(ytrain, ypredict)\n\nplt.rcParams['figure.figsize'] = (5, 5)\nsns.heatmap(cm, annot = True)\nplt.title('Confusion Matrix', fontsize = 20)\nplt.show()\n\nprint(classification_report(y_test,ypredict_test))\n#print(classification_report(ytrain,ypredict))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save model\nimport pickle\nfilename = 'finalized_model.sav'\npickle.dump(clf, open(filename, 'wb'))\nloaded_model = pickle.load(open(filename, 'rb'))\nresult = loaded_model.score(x_test, y_test)\nprint(result)\ny_proba = clf.predict_proba(x_test)\nprint(y_proba)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Random Forest","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report\n\nrfc = RandomForestClassifier(n_estimators=100)\n\nscores = cross_val_score(rfc, x_train[:10,:], y_train[:10], cv=5)\n#print(scores)\nprint(\"Cross validation Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n\nrfc.fit(x_train[:10,:], y_train[:10])\n\n\nypredict_train = rfc.predict(x_train)\nprint(\"Train Accuracy:\",metrics.accuracy_score(y_train, ypredict_train))\n\nypredict_test = rfc.predict(x_test)\nprint(clf.score(x_test,y_test))\nprint(\"Test Accuracy:\",metrics.accuracy_score(y_test, ypredict_test))\n\ncm = confusion_matrix(y_test, ypredict_test)\n# #cm = confusion_matrix(ytrain, ypredict)\n\n# plt.rcParams['figure.figsize'] = (5, 5)\n# sns.heatmap(cm, annot = True)\n# plt.title('Confusion Matrix', fontsize = 20)\n# plt.show()\n\nprint(classification_report(y_test,ypredict_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test1 = \"../input/chest-xray-pneumonia/chest_xray/test/PNEUMONIA/person100_bacteria_477.jpeg\"\ntest0 = \"../input/chest-xray-pneumonia/chest_xray/test/NORMAL/IM-0013-0001.jpeg\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def image_convert2(path,fs):\n    images = []\n    labels = []\n    normal_limit=1\n    p_limit=0\n    img_size=256\n\n    img = cv2.imread(path) \n    if img is not None:\n        img  = cv2.cvtColor(img , cv2.COLOR_BGR2GRAY)   \n        img = cv2.resize(img,(img_size, img_size))\n        images.append(img)\n    images,labels=np.array(images),np.array(labels)\n    \n\n    feature_vector = get_feature_vector(images)\n    \n    return feature_vector\n\n\nfs = np.empty((1,0))\nfs2 = image_convert2(test1,fs)\n\nfs2 = sc.fit_transform(fs2)\nprint(fs2)\ny_prob = clf.predict(fs2)\nprint(y_prob, \"LOLLLLLL\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}